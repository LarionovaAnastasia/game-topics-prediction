# game-topics-prediction

‚ö†Ô∏è Work in progress ‚ö†Ô∏è

A complete end-to-end machine learning project from the initial idea to deployment.
The goal of this project is to create a game topic prediction application.

<img src="https://github.com/LarionovaAnastasia/game-topics-prediction/blob/main/assets/life_run.gif" width="750" height="420" />


üìç The work on this project contains several phases : 

1. Exploratory data analysis 
2. Data cleaning and normalization 
3. Building a training / testing pipeline for a baseline model
4. Traininig production model **(coming soon)**
5. Error analysis **(coming soon)**
6. Setting up API and web extention 
7. Deploying the application and connecting a continuous integration solution **(coming soon)**


# Repo structure

    ‚îú‚îÄ‚îÄ assets                          <- Media files.
    ‚îÇ
    ‚îú‚îÄ‚îÄ config                          <- Configuration files.
    ‚îÇ
    ‚îú‚îÄ‚îÄ data  
    ‚îÇ   ‚îú‚îÄ‚îÄ processed                   <- Intermidiate, transformed data. 
    ‚îÇ   ‚îú‚îÄ‚îÄ raw                         <- The original data
    ‚îÇ   ‚îî‚îÄ‚îÄ splitted                    <- The final data sets for modeling. 
    ‚îÇ
    ‚îú‚îÄ‚îÄ deploy                          <- Scripts for Web extension and Docker deployement                  
    ‚îÇ
    ‚îú‚îÄ‚îÄ game_topics                     <- Source code for use in this project. 
    ‚îÇ   ‚îú‚îÄ‚îÄ models                      <- Scripts to define models. 
    ‚îÇ   ‚îú‚îÄ‚îÄ utils                       <- Scripts with basic utilities used in other scripts. 
    ‚îÇ   ‚îú‚îÄ‚îÄ normalize_and_clean.py      <- Script to normalize and clean the data. 
    ‚îÇ   ‚îî‚îÄ‚îÄ train_model.py              <- Script to train the model.   
    ‚îÇ
    ‚îú‚îÄ‚îÄ model_checkpoints               <- Trained and serialized models, fitted tokenizers and vectorizers. 
    ‚îÇ
    ‚îú‚îÄ‚îÄ notebooks                       <- Jupyter notebooks containing Exploratory Data Analysis and Error Analysis. 
    ‚îÇ
    ‚îú‚îÄ‚îÄ server                          <- Scripts to define the API. 
    ‚îÇ
    ‚îî‚îÄ‚îÄ tests                           <- Testing scripts.


# Data Source 

The data used in this project is publicly available on Kaggle : https://www.kaggle.com/nikdavis/steam-store-games

The original dataset contains 6 files. Only two are used in this project : 
- steam.csv
- steam_description_data.csv

# Features

- **Logistic regression** powered by [Scikit Lean](https://scikit-learn.org/stable/) 
- **CNN model** power by Keras (with Tensorflow background)
- **Exploratory data analysis** using Pandas
- **Data cleaning and normalizing** powered by NLTK and Regex
- **Functionality tests** powered by Unittest
- **Server** via FastAPI and Uvicorn.
- **Chrome extension** for interacting with a model in the browser.
